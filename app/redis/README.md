# ğŸ“¦ Redis in this Project

This project uses **Redis** as a **message queue** to coordinate between the **backend (FastAPI)** and the **AI models service**.

---

## âš™ï¸ What does Redis do?

- ğŸ“¨ **Task Queue** â†’ The backend pushes requests into the queue (`task_queue`).  
- ğŸ¤– **Model Worker** â†’ The models service listens to the queue, processes tasks, and stores results.  
- ğŸ”„ **Backend** â†’ Reads results from Redis and returns them to the frontend.  

ğŸ‘‰ Redis acts as the **intermediary** to ensure tasks are processed asynchronously and reliably.

---

## ğŸ³ How to Run Redis

You already have a `docker-compose.yml` with Redis.  
To start it:

```bash
docker compose up -d
```

This will:  
- Download the official `redis:7` image  
- Create the container `redis_server`  
- Expose port **6379** on your machine  

---

## ğŸ” Verify Redis is Running

You can enter the container and use the CLI client:

```bash
docker exec -it redis_server redis-cli
```

Inside the CLI, try:

```redis
SET test "hello"
GET test
```

You should see:

```
"hello"
```

---

## ğŸ“‚ Project Flow

1. **Frontend** ğŸ‘‰ sends a request to the backend.  
2. **Backend (FastAPI)** ğŸ‘‰ pushes the task into Redis.  
3. **Model Worker** ğŸ‘‰ consumes the task, runs the AI model, and stores the result.  
4. **Backend** ğŸ‘‰ fetches the result and returns it to the frontend.  

---

âœ¨ With Redis, you have the **processing queue engine** ready.
